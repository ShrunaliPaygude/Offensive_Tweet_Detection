{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data set....\n",
      "Done reading....\n"
     ]
    }
   ],
   "source": [
    "print(\"reading data set....\")\n",
    "training_data_set = pd.read_csv(\"/Users/prajwalkrishn/Desktop/My_Computer/project - Dsci 601/Offensive_Tweet_Detection/Dataset/MOLID.csv\")\n",
    "print(\"Done reading....\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is Dubai's like Michael 's phone went pud...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In fact, never was perceived to be thrown. Eve...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhosadi I am your mother's husband. Look at yo...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you ask a dog? And the smoke is drawn throu...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's Ram Kadam went to talk to the BJP and ...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  subtask_a subtask_b  \\\n",
       "0  This is Dubai's like Michael 's phone went pud...  Offensive       UNT   \n",
       "1  In fact, never was perceived to be thrown. Eve...  Offensive       TIN   \n",
       "2  Bhosadi I am your mother's husband. Look at yo...  Offensive       TIN   \n",
       "3  If you ask a dog? And the smoke is drawn throu...  Offensive       TIN   \n",
       "4  Where's Ram Kadam went to talk to the BJP and ...  Offensive       TIN   \n",
       "\n",
       "  subtask_c  \n",
       "0       NaN  \n",
       "1       IND  \n",
       "2       IND  \n",
       "3       IND  \n",
       "4       GRP  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = training_data_set[[\"tweet\"]]\n",
    "level_A_labels = training_data_set[[\"subtask_a\"]]\n",
    "level_B_labels = training_data_set.query(\"subtask_a == 'Offensive'\")[[\"subtask_b\"]]\n",
    "level_C_labels = training_data_set.query(\"subtask_b == 'TIN'\")[[\"subtask_c\"]]\n",
    "\n",
    "All_Cleaned_tweets = copy.deepcopy(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is Dubai's like Michael 's phone went pud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In fact, never was perceived to be thrown. Eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhosadi I am your mother's husband. Look at yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you ask a dog? And the smoke is drawn throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's Ram Kadam went to talk to the BJP and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  This is Dubai's like Michael 's phone went pud...\n",
       "1  In fact, never was perceived to be thrown. Eve...\n",
       "2  Bhosadi I am your mother's husband. Look at yo...\n",
       "3  If you ask a dog? And the smoke is drawn throu...\n",
       "4  Where's Ram Kadam went to talk to the BJP and ..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subtask_a\n",
       "0  Offensive\n",
       "1  Offensive\n",
       "2  Offensive\n",
       "3  Offensive\n",
       "4  Offensive"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_A_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtask_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subtask_b\n",
       "0       UNT\n",
       "1       TIN\n",
       "2       TIN\n",
       "3       TIN\n",
       "4       TIN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_B_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subtask_c\n",
       "1       IND\n",
       "2       IND\n",
       "3       IND\n",
       "4       GRP\n",
       "5       IND"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_C_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is Dubai's like Michael 's phone went pud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In fact, never was perceived to be thrown. Eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhosadi I am your mother's husband. Look at yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you ask a dog? And the smoke is drawn throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's Ram Kadam went to talk to the BJP and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  This is Dubai's like Michael 's phone went pud...\n",
       "1  In fact, never was perceived to be thrown. Eve...\n",
       "2  Bhosadi I am your mother's husband. Look at yo...\n",
       "3  If you ask a dog? And the smoke is drawn throu...\n",
       "4  Where's Ram Kadam went to talk to the BJP and ..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Cleaned_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prajwalkrishn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "lancaster = LancasterStemmer()\n",
    "wordNet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_webTags_UserNames_Noise(tweet):\n",
    "    things_to_be_removed_from_tweets = ['URL','@USER','\\'ve','n\\'t','\\'s','\\'m']\n",
    "    \n",
    "    for things in things_to_be_removed_from_tweets:\n",
    "        tweet = tweet.replace(things,'')\n",
    "    \n",
    "    return re.sub(r'[^a-zA-Z]', ' ', tweet)\n",
    "\n",
    "def tokenize(tweet):\n",
    "    lower_cased_tweet = tweet.lower()\n",
    "    return word_tokenize(lower_cased_tweet)\n",
    "\n",
    "def stop_words_removal(tokens):\n",
    "    cleaned_tokens = []\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for token in tokens:\n",
    "        if token not in stop:\n",
    "            if token.replace(' ','') != '':\n",
    "                if len(token) > 1:\n",
    "                    cleaned_tokens.append(token)\n",
    "    return cleaned_tokens\n",
    "\n",
    "def stemming(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        token = lancaster.stem(token)\n",
    "        if len(token) > 1:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens\n",
    "\n",
    "def lemmatization(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        token = wordNet.lemmatize(token)\n",
    "        if len(token) > 1:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean...: 100%|██████████| 2499/2499 [00:00<00:00, 89430.87it/s]\n",
      "Tokenize..: 100%|██████████| 2499/2499 [00:00<00:00, 10439.78it/s]\n",
      "remove STOPWORDS...: 100%|██████████| 2499/2499 [00:00<00:00, 12270.28it/s]\n",
      "Stemming...: 100%|██████████| 2499/2499 [00:00<00:00, 12173.92it/s]\n",
      "Lemmatize...: 100%|██████████| 2499/2499 [00:00<00:00, 39699.44it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc = \"clean...\")\n",
    "All_Cleaned_tweets['tweet'] = tweets['tweet'].progress_apply(remove_webTags_UserNames_Noise)\n",
    "\n",
    "tqdm.pandas(desc=\"Tokenize..\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tweet'].progress_apply(tokenize)\n",
    "\n",
    "tqdm.pandas(desc=\"remove STOPWORDS...\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tokens'].progress_apply(stop_words_removal)\n",
    "\n",
    "tqdm.pandas(desc=\"Stemming...\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tokens'].progress_apply(stemming)\n",
    "\n",
    "tqdm.pandas(desc=\"Lemmatize...\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tokens'].progress_apply(lemmatization)\n",
    "\n",
    "text_vector = All_Cleaned_tweets['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is Dubai like Michael  phone went pudica</td>\n",
       "      <td>[duba, lik, michael, phon, went, pudic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In fact  never was perceived to be thrown  Eve...</td>\n",
       "      <td>[fact, nev, perceiv, thrown, everyth, mov, tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhosadi I am your mother husband  Look at your...</td>\n",
       "      <td>[bhosad, moth, husband, look, moth, as, kil, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you ask a dog  And the smoke is drawn throu...</td>\n",
       "      <td>[ask, dog, smok, drawn, rub, goat, alon, kang,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where Ram Kadam went to talk to the BJP and no...</td>\n",
       "      <td>[ram, kadam, went, talk, bjp, behavy, mut, con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0     This is Dubai like Michael  phone went pudica    \n",
       "1  In fact  never was perceived to be thrown  Eve...   \n",
       "2  Bhosadi I am your mother husband  Look at your...   \n",
       "3  If you ask a dog  And the smoke is drawn throu...   \n",
       "4  Where Ram Kadam went to talk to the BJP and no...   \n",
       "\n",
       "                                              tokens  \n",
       "0            [duba, lik, michael, phon, went, pudic]  \n",
       "1  [fact, nev, perceiv, thrown, everyth, mov, tow...  \n",
       "2  [bhosad, moth, husband, look, moth, as, kil, d...  \n",
       "3  [ask, dog, smok, drawn, rub, goat, alon, kang,...  \n",
       "4  [ram, kadam, went, talk, bjp, behavy, mut, con...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Cleaned_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfid(text_vector):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    untokenized_data =[' '.join(tweet) for tweet in tqdm(text_vector, \"Vectorizing...\")]\n",
    "    vectorizer = vectorizer.fit(untokenized_data)\n",
    "    vectors = vectorizer.transform(untokenized_data).toarray()\n",
    "    return vectors\n",
    "  \n",
    "def get_vectors(vectors, labels, keyword):\n",
    "    if len(vectors) != len(labels):\n",
    "        print(\"Unmatching sizes!\")\n",
    "        return\n",
    "    result = list()\n",
    "    for vector, label in zip(vectors, labels):\n",
    "        if label == keyword:\n",
    "            result.append(vector)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing...: 100%|██████████| 2499/2499 [00:00<00:00, 1764870.47it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors_level_a = tfid(text_vector) # Numerical Vectors A\n",
    "labels_level_a = level_A_labels['subtask_a'].values.tolist() # Subtask A Labels\n",
    "\n",
    "vectors_level_b = get_vectors(vectors_level_a, labels_level_a, \"Offensive\") # Numerical Vectors B\n",
    "labels_level_b = level_B_labels['subtask_b'].values.tolist() # Subtask B Labels\n",
    "\n",
    "vectors_level_c = get_vectors(vectors_level_b, labels_level_b, \"TIN\") # Numerical Vectors C\n",
    "labels_level_c = level_C_labels['subtask_c'].values.tolist() # Subtask C Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(vectors_level_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     nan,\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'GRP',\n",
      "     'OTH',\n",
      "     'GRP',\n",
      "     'GRP',\n",
      "     'IND',\n",
      "     'IND',\n",
      "     'OTH',\n",
      "     'IND']\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(labels_level_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit begins...\n",
      "fit complete....\n",
      "calculating accuracy....\n",
      "Training Accuracy: 0.991462113127001\n",
      "Test Accuracy: 0.8544\n",
      "Confusion Matrix:\n",
      "[[171  45]\n",
      " [ 46 363]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Offensive       0.79      0.79      0.79       216\n",
      "not offensive       0.89      0.89      0.89       409\n",
      "\n",
      "     accuracy                           0.85       625\n",
      "    macro avg       0.84      0.84      0.84       625\n",
      " weighted avg       0.85      0.85      0.85       625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "# print(\"splitting and fitting on level A annotations....\")\n",
    "# train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors_level_a[:], labels_level_a[:], train_size=0.70)\n",
    "# print(\"split done...\")\n",
    "\n",
    "train_vectors_b, test_vectors_b, train_labels_b, test_labels_b = train_test_split(vectors_level_a[:], labels_level_a[:], train_size=0.75)\n",
    "\n",
    "print(\"fit begins...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "classifier = DecisionTreeClassifier(max_depth=800, min_samples_split=5)\n",
    "params = {'criterion':['gini','entropy']}\n",
    "classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
    "classifier.fit(train_vectors_b, train_labels_b)\n",
    "classifier = classifier.best_estimator_\n",
    "print(\"fit complete....\")\n",
    "\n",
    "print(\"calculating accuracy....\")\n",
    "accuracy = accuracy_score(train_labels_b, classifier.predict(train_vectors_b))\n",
    "print(\"Training Accuracy:\", accuracy)\n",
    "test_predictions = classifier.predict(test_vectors_b)\n",
    "accuracy = accuracy_score(test_labels_b, test_predictions)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\", )\n",
    "print(confusion_matrix(test_labels_b, test_predictions))\n",
    "print(classification_report(test_labels_b,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model experiment begins ...\n",
      "fit begins...\n",
      "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   9.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   9.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   9.3s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   9.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   9.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   7.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   7.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   7.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   7.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   7.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   9.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   9.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   9.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   9.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=  10.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   9.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   9.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   9.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   9.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   9.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   9.6s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   9.6s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   9.7s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   9.6s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   9.7s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   9.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   9.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM model experiment begins ...\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors_level_a[:], labels_level_a[:], train_size=0.70)\n",
    "\n",
    "print(\"fit begins...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "classifiersvc = SVC()\n",
    "print(classifiersvc.get_params().keys())\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]}]\n",
    "classifierGrid = GridSearchCV(classifiersvc, param_grid, refit = True, verbose=2)\n",
    "classifierGrid.fit(train_vectors, train_labels)\n",
    "classifierGrid = classifierGrid.best_estimator_\n",
    "print(\"fit complete....\")\n",
    "\n",
    "\n",
    "print(\"calculating accuracy....\")\n",
    "accuracy = accuracy_score(train_labels, classifierGrid.predict(train_vectors))\n",
    "print(\"Training Accuracy:\", accuracy)\n",
    "test_predictions = classifierGrid.predict(test_vectors)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\", )\n",
    "print(confusion_matrix(test_labels, test_predictions))\n",
    "print(classification_report(test_labels,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
