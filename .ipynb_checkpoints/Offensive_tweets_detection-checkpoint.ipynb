{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data set....\n",
      "Done reading....\n"
     ]
    }
   ],
   "source": [
    "print(\"reading data set....\")\n",
    "training_data_set = pd.read_csv(\"/Users/prajwalkrishn/Desktop/My_Computer/project - Dsci 601/Offensive_Tweet_Detection/Dataset/MOLID.csv\")\n",
    "print(\"Done reading....\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is Dubai's like Michael 's phone went pud...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In fact, never was perceived to be thrown. Eve...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhosadi I am your mother's husband. Look at yo...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you ask a dog? And the smoke is drawn throu...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's Ram Kadam went to talk to the BJP and ...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  subtask_a subtask_b  \\\n",
       "0  This is Dubai's like Michael 's phone went pud...  Offensive       UNT   \n",
       "1  In fact, never was perceived to be thrown. Eve...  Offensive       TIN   \n",
       "2  Bhosadi I am your mother's husband. Look at yo...  Offensive       TIN   \n",
       "3  If you ask a dog? And the smoke is drawn throu...  Offensive       TIN   \n",
       "4  Where's Ram Kadam went to talk to the BJP and ...  Offensive       TIN   \n",
       "\n",
       "  subtask_c  \n",
       "0       NaN  \n",
       "1       IND  \n",
       "2       IND  \n",
       "3       IND  \n",
       "4       GRP  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = training_data_set[[\"tweet\"]]\n",
    "level_A_labels = training_data_set[[\"subtask_a\"]]\n",
    "level_B_labels = training_data_set.query(\"subtask_a == 'Offensive'\")[[\"subtask_b\"]]\n",
    "level_C_labels = training_data_set.query(\"subtask_b == 'TIN'\")[[\"subtask_c\"]]\n",
    "\n",
    "All_Cleaned_tweets = copy.deepcopy(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is Dubai's like Michael 's phone went pud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In fact, never was perceived to be thrown. Eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhosadi I am your mother's husband. Look at yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you ask a dog? And the smoke is drawn throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's Ram Kadam went to talk to the BJP and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  This is Dubai's like Michael 's phone went pud...\n",
       "1  In fact, never was perceived to be thrown. Eve...\n",
       "2  Bhosadi I am your mother's husband. Look at yo...\n",
       "3  If you ask a dog? And the smoke is drawn throu...\n",
       "4  Where's Ram Kadam went to talk to the BJP and ..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subtask_a\n",
       "0  Offensive\n",
       "1  Offensive\n",
       "2  Offensive\n",
       "3  Offensive\n",
       "4  Offensive"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_A_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtask_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subtask_b\n",
       "0       UNT\n",
       "1       TIN\n",
       "2       TIN\n",
       "3       TIN\n",
       "4       TIN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_B_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subtask_c\n",
       "1       IND\n",
       "2       IND\n",
       "3       IND\n",
       "4       GRP\n",
       "5       IND"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_C_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is Dubai's like Michael 's phone went pud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In fact, never was perceived to be thrown. Eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhosadi I am your mother's husband. Look at yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you ask a dog? And the smoke is drawn throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's Ram Kadam went to talk to the BJP and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  This is Dubai's like Michael 's phone went pud...\n",
       "1  In fact, never was perceived to be thrown. Eve...\n",
       "2  Bhosadi I am your mother's husband. Look at yo...\n",
       "3  If you ask a dog? And the smoke is drawn throu...\n",
       "4  Where's Ram Kadam went to talk to the BJP and ..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Cleaned_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "lancaster = LancasterStemmer()\n",
    "wordNet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_webTags_UserNames_Noise(tweet):\n",
    "    things_to_be_removed_from_tweets = ['URL','@USER','\\'ve','n\\'t','\\'s','\\'m']\n",
    "    \n",
    "    for things in things_to_be_removed_from_tweets:\n",
    "        tweet = tweet.replace(things,'')\n",
    "    \n",
    "    return re.sub(r'[^a-zA-Z]', ' ', tweet)\n",
    "\n",
    "def tokenize(tweet):\n",
    "    lower_cased_tweet = tweet.lower()\n",
    "    return word_tokenize(lower_cased_tweet)\n",
    "\n",
    "def stop_words_removal(tokens):\n",
    "    cleaned_tokens = []\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for token in tokens:\n",
    "        if token not in stop:\n",
    "            if token.replace(' ','') != '':\n",
    "                if len(token) > 1:\n",
    "                    cleaned_tokens.append(token)\n",
    "    return cleaned_tokens\n",
    "\n",
    "def stemming(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        token = lancaster.stem(token)\n",
    "        if len(token) > 1:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens\n",
    "\n",
    "def lemmatization(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        token = wordNet.lemmatize(token)\n",
    "        if len(token) > 1:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc = \"clean...\")\n",
    "All_Cleaned_tweets['tweet'] = tweets['tweet'].progress_apply(remove_webTags_UserNames_Noise)\n",
    "\n",
    "tqdm.pandas(desc=\"Tokenize..\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tweet'].progress_apply(tokenize)\n",
    "\n",
    "tqdm.pandas(desc=\"remove STOPWORDS...\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tokens'].progress_apply(stop_words_removal)\n",
    "\n",
    "tqdm.pandas(desc=\"Stemming...\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tokens'].progress_apply(stemming)\n",
    "\n",
    "tqdm.pandas(desc=\"Lemmatize...\")\n",
    "All_Cleaned_tweets['tokens'] = All_Cleaned_tweets['tokens'].progress_apply(lemmatization)\n",
    "\n",
    "text_vector = All_Cleaned_tweets['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Cleaned_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfid(text_vector):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    untokenized_data =[' '.join(tweet) for tweet in tqdm(text_vector, \"Vectorizing...\")]\n",
    "    vectorizer = vectorizer.fit(untokenized_data)\n",
    "    vectors = vectorizer.transform(untokenized_data).toarray()\n",
    "    return vectors\n",
    "  \n",
    "def get_vectors(vectors, labels, keyword):\n",
    "    if len(vectors) != len(labels):\n",
    "        print(\"Unmatching sizes!\")\n",
    "        return\n",
    "    result = list()\n",
    "    for vector, label in zip(vectors, labels):\n",
    "        if label == keyword:\n",
    "            result.append(vector)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_level_a = tfid(text_vector) # Numerical Vectors A\n",
    "labels_level_a = level_A_labels['subtask_a'].values.tolist() # Subtask A Labels\n",
    "\n",
    "vectors_level_b = get_vectors(vectors_level_a, labels_level_a, \"Offensive\") # Numerical Vectors B\n",
    "labels_level_b = level_B_labels['subtask_b'].values.tolist() # Subtask B Labels\n",
    "\n",
    "vectors_level_c = get_vectors(vectors_level_b, labels_level_b, \"TIN\") # Numerical Vectors C\n",
    "labels_level_c = level_C_labels['subtask_c'].values.tolist() # Subtask C Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(vectors_level_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(labels_level_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "# print(\"splitting and fitting on level A annotations....\")\n",
    "# train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors_level_a[:], labels_level_a[:], train_size=0.70)\n",
    "# print(\"split done...\")\n",
    "\n",
    "train_vectors_b, test_vectors_b, train_labels_b, test_labels_b = train_test_split(vectors_level_a[:], labels_level_a[:], train_size=0.75)\n",
    "\n",
    "print(\"fit begins...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "classifier = DecisionTreeClassifier(max_depth=800, min_samples_split=5)\n",
    "params = {'criterion':['gini','entropy']}\n",
    "classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
    "classifier.fit(train_vectors_b, train_labels_b)\n",
    "classifier = classifier.best_estimator_\n",
    "print(\"fit complete....\")\n",
    "\n",
    "print(\"calculating accuracy....\")\n",
    "accuracy = accuracy_score(train_labels_b, classifier.predict(train_vectors_b))\n",
    "print(\"Training Accuracy:\", accuracy)\n",
    "test_predictions = classifier.predict(test_vectors_b)\n",
    "accuracy = accuracy_score(test_labels_b, test_predictions)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\", )\n",
    "print(confusion_matrix(test_labels_b, test_predictions))\n",
    "print(classification_report(test_labels_b,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM model experiment begins ...\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors_level_a[:], labels_level_a[:], train_size=0.70)\n",
    "\n",
    "print(\"fit begins...\")\n",
    "warnings.filterwarnings(action='ignore')\n",
    "classifier = LinearSVC()\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
    "classifier.fit(train_vectors, train_labels)\n",
    "classifier = classifier.best_estimator_\n",
    "print(\"fit complete....\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
